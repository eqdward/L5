Thinking1：在CTR点击率预估中，使用GBDT+LR的原理是什么？
答：

学习能力有限，以往的CTR预估采用LR模型，LR是线性模型，虽然速度较快，但是学习能力有限
人工成本高，为了更好的进行特征提取，提升LR的学习能力，需要采用人工特征工程，即通过人工方式找到有区分度的特征、特征组合。对人的要求高，时间成本高
Thinking：如何自动发现有效的特征及特征组合，弥补人工经验不足，缩短LR实验周期

具有stacking思想的二分类器模型，用来解决二分类问题
通过GBDT将特征进行组合，然后传入给线性分类器
LR对GBDT产生的输入数据进行分类（使用L1正则化防止过拟合）

当GBDT训练好做预测的时候，输出的并不是最终的二分类概率值，而是要把模型中的每棵树计算得到的预测概率值所属的叶子结点位置记为1 => 构造新的训练数据

有了正确的特征（基于决策树）和模型（基于LR），对预测结果的影响最大，其他的影响因素都不大
GBDT是一种常用的非线性模型，基于集成学习中的boosting思想，也就是每次迭代都在减少残差的梯度方向新建立一颗决策树，迭代多少次就会生成多少颗决策树。
GBDT得到的特征、特征组合都具有区分性，在特征选择上不亚于人工经验的处理方式


Thinking2：Wide & Deep的模型结构是怎样的，为什么能通过具备记忆和泛化能力（memorization and generalization）
Thinking3：在CTR预估中，使用FM与DNN结合的方式，有哪些结合的方式，代表模型有哪些？
Thinking4：GBDT和随机森林都是基于树的算法，它们有什么区别？
答：Boosting，通过将弱学习器提升为强学习器的集成方法来提高预测精度（比如AdaBoost，GBDT）
Bagging，通过自助采样的方法生成众多并行式的分类器，通过“少数服从多数”的原则来确定最终的结果（比如Random Forest）



Thinking5：item流行度在推荐系统中有怎样的应用
